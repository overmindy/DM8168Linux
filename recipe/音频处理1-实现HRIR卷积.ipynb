{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 介绍\n",
    "```\n",
    "    对空间音效做一个简要介绍，如果我们想要听到3D空间音效，有一个方法就是用很多扬声器布局构造一个顶级的播放环境，在合适的位置能够享受到极致的听觉体验；但是，无论传来的声音多么立体，声音只会从两个耳朵接受，所以我们能否实现在耳朵处，直接播放3D空间音效的声波到达的音频，直接实现3D音效；方法就是，相同的音频，到达左右耳，会在不同频率有所改变，也就是经过了不同冲激响应函数系统，这点微小的改变会使得耳朵分辨出方位；于是人们测出了不同位置到达耳朵时的冲击响应函数，做到空间音效处理。\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.前置准备\n",
    "1. 首先安装一下可能会用到的库并导入\n",
    "2. 完成基本的读入音频和写入音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.signal import resample, convolve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取wav文件\n",
    "def read_wav(filename):\n",
    "    Fs, data = wav.read(filename)\n",
    "    return Fs, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 写入wav文件\n",
    "def write_wav(filename, Fs, data):\n",
    "    wav.write(filename, Fs, data.astype(np.int16))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 重采样函数，用于改变音频的采样率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 重采样函数\n",
    "def resample_audio(data, original_fs, new_fs):\n",
    "    num_samples = int(len(data) * float(new_fs) / original_fs)\n",
    "    return resample(data, num_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二.实现音频处理函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这里音频函数会接受两个声道的数据，两个声道的HRIR和前后采样率\n",
    "2. 先进行重采样\n",
    "3. 将左右声道和冲激串做一维卷积\n",
    "4. 合成左右声道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 处理单声道音频进行卷积\n",
    "def process_audio(L,R, hrir_l, hrir_r, Fs, new_fs):\n",
    "    # 重采样音频\n",
    "    resampled_audio_L = resample_audio(L,Fs,new_fs)\n",
    "    resampled_audio_R = resample_audio(R,Fs,new_fs)\n",
    "    # 分别与左右HRIR卷积\n",
    "    out_l = convolve(resampled_audio_L, hrir_l)\n",
    "    out_r = convolve(resampled_audio_R, hrir_r)\n",
    "    \n",
    "    # 合成立体声\n",
    "    out_stereo = np.column_stack((out_l, out_r))\n",
    "    return out_stereo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.进行实验测试\n",
    "1. 读取HRIR数据用于对音频卷积处理\n",
    "2. 对冲激串进行放缩操作，可以理解单位化，避免得到的音频数据过大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_path='full\\\\elev60\\\\L60e250a.wav'\n",
    "R_path='full\\\\elev60\\\\R60e250a.wav'\n",
    "# 读取HRIR数据\n",
    "Fs_hrir, hrir_l = read_wav(L_path)\n",
    "_, hrir_r = read_wav(R_path)\n",
    "hrir_l,hrir_r=hrir_l*0.00005,hrir_r*0.00005\n",
    "print(max(hrir_l),max(hrir_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 读取音频文件，得到左右声道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 读取音频文件\n",
    "Fs, audio_data = read_wav('test.wav')\n",
    "if len(audio_data[0])==2:\n",
    "    audio_data_LL=[data[0] for data in audio_data]\n",
    "    audio_data_RR=[data[1] for data in audio_data]\n",
    "    print(\"双声道\")\n",
    "else:\n",
    "    print('单声道')\n",
    "print(max(audio_data_LL),max(audio_data_RR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 实现音频处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置目标采样率\n",
    "new_fs = 48000\n",
    "\n",
    "# 处理音频，进行卷积并生成立体声\n",
    "processed_audio = process_audio(audio_data_LL,audio_data_RR, hrir_l, hrir_r, Fs, new_fs)\n",
    "\n",
    "# 将处理后的音频写入文件\n",
    "write_wav('processed_audio.wav', new_fs, processed_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(processed_audio))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
